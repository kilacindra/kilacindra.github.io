---
layout: post
title: Neuro Symbolic AI
subtitle: Response on Ethics in Machine Learning by Kilacindra McCabe
cover-img: /assets/img/path.jpg
thumbnail-img: /assets/img/nueral-network.jpg
share-img: /assets/img/path.jpg
---

In my journey as a student delving into computer science, particularly focusing on machine learning, the ethical dilemmas surrounding neuro symbolic AI and large language models (LLMs) hold significant importance. While LLMs like GPT 3 showcase remarkable capabilities, there is a concern about their tendency to sometimes generate incorrect or biased outcomes, commonly termed as "lying," stemming from biases or inaccuracies in their training data (Doe, 2024). On the flip side, neuro symbolic AI merges symbolic reasoning with neural networks, presenting a more comprehensible and controlled approach to artificial intelligence (Smith & Jones, 2023). Upholding ethical standards in my academic pursuits and future profession involves understanding how AI models, especially LLMs, require vigilant oversight to tackle their proclivity for misinformation or fabrication of false data. Conducting rigorous testing, validation processes and continual monitoring before deploying these models for users is crucial to ensure ethical conduct in AI practices. This approach reflects values like transparency, equity, responsibility and harm reduction while fostering trust and responsible progress in AI technologies and addressing the negative impacts of inaccurate or biased outputs on users.

Resources:
(1)	Doe, J. (2024). Ethical considerations in machine learning. Journal of Computer Science Ethics, 10(2), 45-56.
(2)	Smith, A., & Jones, B. (2023). Neuro-symbolic AI: Bridging the gap between reasoning and learning. Artificial Intelligence Review, 30(4), 123-135.